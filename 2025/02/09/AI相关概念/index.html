<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="AI相关概念解析第一章：大语言模型（LLM）核心技术1.1 核心定义与特性 定义: 基于深度学习的超大规模语言模型（参数规模达10^11~10^12量级） 典型代表: GPT-3&#x2F;4（OpenAI） PaLM（Google） Llama（Meta）   三大核心特征： 大规模参数: 如GPT-3含1750亿参数 海量训练数据: GPT-3训练数据包含数千亿单词 算力密集型: 依赖GPU&amp;">
<meta property="og:type" content="article">
<meta property="og:title" content="AI相关概念">
<meta property="og:url" content="http://example.com/2025/02/09/AI%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/index.html">
<meta property="og:site_name" content="SYL">
<meta property="og:description" content="AI相关概念解析第一章：大语言模型（LLM）核心技术1.1 核心定义与特性 定义: 基于深度学习的超大规模语言模型（参数规模达10^11~10^12量级） 典型代表: GPT-3&#x2F;4（OpenAI） PaLM（Google） Llama（Meta）   三大核心特征： 大规模参数: 如GPT-3含1750亿参数 海量训练数据: GPT-3训练数据包含数千亿单词 算力密集型: 依赖GPU&amp;">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-02-09T05:17:23.000Z">
<meta property="article:modified_time" content="2025-02-11T03:42:29.105Z">
<meta property="article:author" content="songyanglin">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2025/02/09/AI%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/02/09/AI%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","path":"2025/02/09/AI相关概念/","title":"AI相关概念"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AI相关概念 | SYL</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SYL</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">随笔</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-navigation"><a href="/navigation/" rel="section"><i class="fa fa-navicon fa-fw"></i>导航</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#AI%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E8%A7%A3%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">AI相关概念解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF"><span class="nav-number">1.1.</span> <span class="nav-text">第一章：大语言模型（LLM）核心技术</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E6%A0%B8%E5%BF%83%E5%AE%9A%E4%B9%89%E4%B8%8E%E7%89%B9%E6%80%A7"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1 核心定义与特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Transformer%E6%9E%B6%E6%9E%84"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2 Transformer架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-Token"><span class="nav-number">1.1.3.</span> <span class="nav-text">1.3 Token</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF-Token%EF%BC%9F"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">一、什么是 Token？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-Token%EF%BC%9F"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">二、为什么需要 Token？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E3%80%81Token-%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="nav-number">1.1.3.3.</span> <span class="nav-text">三、Token 如何影响模型？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.1.3.4.</span> <span class="nav-text">四、实际应用示例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93"><span class="nav-number">1.1.3.5.</span> <span class="nav-text">五、总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9AAI%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB%E4%BD%93%E7%B3%BB"><span class="nav-number">1.2.</span> <span class="nav-text">第二章：AI模型分类体系</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E5%88%86%E7%B1%BB%E7%BB%B4%E5%BA%A6"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 分类维度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E5%85%B8%E5%9E%8B%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 典型模型详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B%EF%BC%88Chat-Model%EF%BC%89"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">对话模型（Chat Model）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%EF%BC%88Coder-Model%EF%BC%89"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">代码生成模型（Coder Model）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">多模态模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%EF%BC%88Embedding-Model%EF%BC%89"><span class="nav-number">1.2.2.4.</span> <span class="nav-text">嵌入模型（Embedding Model）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%EF%BC%88RAG%EF%BC%89%E6%8A%80%E6%9C%AF%E4%BD%93%E7%B3%BB"><span class="nav-number">1.3.</span> <span class="nav-text">第三章：检索增强生成（RAG）技术体系</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-RAG-%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">1.3.1.</span> <span class="nav-text">3.1 RAG 的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E6%B5%81%E7%A8%8B%E6%8B%86%E8%A7%A3"><span class="nav-number">1.3.2.</span> <span class="nav-text">3.2 流程拆解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3RAG-%E8%BF%90%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%A7%A3"><span class="nav-number">1.3.3.</span> <span class="nav-text">3.3RAG 运作流程图解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4%E6%B5%81%E7%A8%8B%E5%88%86%E6%AD%A5%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.3.4.</span> <span class="nav-text">3.4流程分步详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E7%94%A8%E6%88%B7%E9%97%AE%E9%A2%98%E5%90%91%E9%87%8F%E5%8C%96"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">1. 用户问题向量化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8C%B9%E9%85%8D"><span class="nav-number">1.3.4.2.</span> <span class="nav-text">2. 向量数据库匹配</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%8C%B9%E9%85%8D%E6%88%90%E5%8A%9F%EF%BC%9A%E5%9F%BA%E4%BA%8E%E7%9F%A5%E8%AF%86%E5%BA%93%E5%9B%9E%E7%AD%94"><span class="nav-number">1.3.4.3.</span> <span class="nav-text">3. 匹配成功：基于知识库回答</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E5%8C%B9%E9%85%8D%E5%A4%B1%E8%B4%A5%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%87%AA%E4%B8%BB%E5%9B%9E%E7%AD%94"><span class="nav-number">1.3.4.4.</span> <span class="nav-text">4. 匹配失败：大模型自主回答</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5%E7%B1%BB%E6%AF%94"><span class="nav-number">1.3.5.</span> <span class="nav-text">3.5类比</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BE%8B%E5%B8%88-%E6%89%8B%E5%86%8C"><span class="nav-number">1.3.5.1.</span> <span class="nav-text">律师 + 手册</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8F%9C%E9%B8%9F%E5%8E%A8%E5%B8%88-%E9%A3%9F%E6%9D%90%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F"><span class="nav-number">1.3.5.2.</span> <span class="nav-text">菜鸟厨师 + 食材检索系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%A2%E6%9C%8D%E4%B8%93%E5%91%98-%E7%9F%A5%E8%AF%86%E5%BA%93%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E"><span class="nav-number">1.3.5.3.</span> <span class="nav-text">客服专员 + 知识库搜索引擎</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5%E5%B8%B8%E8%A7%81%E7%9A%84%E8%AF%AF%E8%A7%A3%E4%BF%AE%E6%AD%A3"><span class="nav-number">1.3.6.</span> <span class="nav-text">3.5常见的误解修正</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AF%E8%A7%A3-1%EF%BC%9A%E2%80%9C%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%E7%9B%B4%E6%8E%A5%E5%B0%86%E7%9F%A5%E8%AF%86%E4%BC%A0%E6%8E%88%E7%BB%99-AI%E2%80%9D"><span class="nav-number">1.3.6.1.</span> <span class="nav-text">误解 1：“嵌入模型直接将知识传授给 AI”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AF%E8%A7%A3-2%EF%BC%9A%E2%80%9C%E7%9F%A5%E8%AF%86%E5%BA%93%E6%98%AF%E6%9F%90%E7%A7%8D%E7%89%B9%E6%AE%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E2%80%9D"><span class="nav-number">1.3.6.2.</span> <span class="nav-text">误解 2：“知识库是某种特殊数据结构”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AF%E8%A7%A3-3%EF%BC%9A%E2%80%9CRAG-%E5%8F%AA%E6%98%AF%E6%8A%8A%E6%95%B0%E6%8D%AE%E7%81%8C%E7%BB%99%E6%A8%A1%E5%9E%8B%E2%80%9D"><span class="nav-number">1.3.6.3.</span> <span class="nav-text">误解 3：“RAG 只是把数据灌给模型”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%8F%E5%B7%AE%E7%82%B9-1%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E2%80%9C%E4%B8%BB%E5%8A%A8%E6%80%A7%E2%80%9D%E9%97%AE%E9%A2%98"><span class="nav-number">1.3.6.4.</span> <span class="nav-text">偏差点 1：大模型的“主动性”问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%8F%E5%B7%AE%E7%82%B9-2%EF%BC%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E7%9A%84%E6%A3%80%E7%B4%A2%E7%B2%BE%E5%BA%A6"><span class="nav-number">1.3.6.5.</span> <span class="nav-text">偏差点 2：知识库的检索精度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%8F%E5%B7%AE%E7%82%B9-3%EF%BC%9ARAG-%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%BE%B9%E7%95%8C"><span class="nav-number">1.3.6.6.</span> <span class="nav-text">偏差点 3：RAG 的可靠性边界</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-6%E6%80%BB%E7%BB%93"><span class="nav-number">1.3.7.</span> <span class="nav-text">3.6总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0Prompt%EF%BC%88%E6%8F%90%E7%A4%BA%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%89"><span class="nav-number">1.4.</span> <span class="nav-text">第四章Prompt（提示提示词）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-%E5%AE%9A%E4%B9%89%E4%BB%BB%E5%8A%A1%E7%9B%AE%E6%A0%87"><span class="nav-number">1.4.1.</span> <span class="nav-text">4.1 定义任务目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-%E6%8E%A7%E5%88%B6%E8%BE%93%E5%87%BA%E9%A3%8E%E6%A0%BC%E4%B8%8E%E6%A0%BC%E5%BC%8F"><span class="nav-number">1.4.2.</span> <span class="nav-text">4.2 控制输出风格与格式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-%E6%8F%90%E4%BE%9B%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%8E%E7%BA%A6%E6%9D%9F"><span class="nav-number">1.4.3.</span> <span class="nav-text">4.3 提供上下文与约束</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-%E6%BF%80%E6%B4%BB%E7%89%B9%E5%AE%9A%E7%9F%A5%E8%AF%86%E6%88%96%E8%83%BD%E5%8A%9B"><span class="nav-number">1.4.4.</span> <span class="nav-text">4.4 激活特定知识或能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-%E7%BA%A0%E6%AD%A3%E5%81%8F%E5%B7%AE%E4%B8%8E%E5%AE%89%E5%85%A8%E5%AF%B9%E9%BD%90"><span class="nav-number">1.4.5.</span> <span class="nav-text">4.5 纠正偏差与安全对齐</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%EF%BC%88Few-shot-Learning%EF%BC%89"><span class="nav-number">1.4.6.</span> <span class="nav-text">4.6 提升效率（Few-shot Learning）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-7-%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E6%A8%A1%E5%9E%8B%E8%A1%8C%E4%B8%BA"><span class="nav-number">1.4.7.</span> <span class="nav-text">4.7 动态调整模型行为</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-8-%E5%85%B3%E9%94%AE%E6%8C%91%E6%88%98%E4%B8%8E%E4%BC%98%E5%8C%96"><span class="nav-number">1.4.8.</span> <span class="nav-text">4.8 关键挑战与优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-9-%E6%80%BB%E7%BB%93"><span class="nav-number">1.4.9.</span> <span class="nav-text">4.9 总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0AI-Agent%EF%BC%88%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86%EF%BC%89"><span class="nav-number">1.5.</span> <span class="nav-text">第五章AI Agent（人工智能代理）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-AI-Agent%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%A0%B8%E5%BF%83%E7%89%B9%E6%80%A7"><span class="nav-number">1.5.1.</span> <span class="nav-text">5.1 AI Agent的定义与核心特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88"><span class="nav-number">1.5.2.</span> <span class="nav-text">5.2 核心流程概览</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-AI-Agent-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86"><span class="nav-number">1.5.3.</span> <span class="nav-text">5.3 AI Agent 的核心组成部分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-AI-Agent-%E7%9A%84%E5%88%86%E7%B1%BB"><span class="nav-number">1.5.4.</span> <span class="nav-text">5.4 AI Agent 的分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-AI-Agent-%E7%9A%84%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.5.5.</span> <span class="nav-text">5.5 AI Agent 的典型应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-6-AI-Agent-%E4%B8%8ELLM%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">1.5.6.</span> <span class="nav-text">5.6 AI Agent 与LLM的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-%E6%80%BB%E7%BB%93"><span class="nav-number">1.5.7.</span> <span class="nav-text">5.7 总结</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">songyanglin</p>
  <div class="site-description" itemprop="description">code随笔</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Songyanglin-curious" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Songyanglin-curious" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
<!-- recent posts -->
    <div class="links-of-blogroll motion-element links-of-blogroll-block">
        <div class="links-of-blogroll-title recent-posts-title">
	    <i class="fa fa-history " aria-hidden="true"></i>
            近期文章
	</div>
	<ul class="links-of-blogroll-list recent-posts-list">
	        <li class="my-links-of-blogroll-item">
		    <a href="/2025/02/10/DeepSeek%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/" title="DeepSeek部署记录" target="">
		    DeepSeek部署记录
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/2025/02/09/AI%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/" title="AI相关概念" target="">
		    AI相关概念
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/2025/02/07/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/" title="浏览器开发工具" target="">
		    浏览器开发工具
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/2025/02/07/%E5%8F%AF%E8%A7%86%E5%8C%96%E7%95%8C%E9%9D%A2%E7%94%9F%E6%88%90%E5%99%A8/" title="可视化界面生成器" target="">
		    可视化界面生成器
		    </a>
		</li>
	        <li class="my-links-of-blogroll-item">
		    <a href="/2025/02/06/AI%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E5%B7%A7%E5%8F%8A%E7%A4%BA%E4%BE%8B/" title="AI提示词技巧及示例" target="">
		    AI提示词技巧及示例
		    </a>
		</li>
	</ul>
    </div>
        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/09/AI%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="songyanglin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SYL">
      <meta itemprop="description" content="code随笔">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="AI相关概念 | SYL">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AI相关概念
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-09 13:17:23" itemprop="dateCreated datePublished" datetime="2025-02-09T13:17:23+08:00">2025-02-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-02-11 11:42:29" itemprop="dateModified" datetime="2025-02-11T11:42:29+08:00">2025-02-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="AI相关概念解析"><a href="#AI相关概念解析" class="headerlink" title="AI相关概念解析"></a>AI相关概念解析</h1><h2 id="第一章：大语言模型（LLM）核心技术"><a href="#第一章：大语言模型（LLM）核心技术" class="headerlink" title="第一章：大语言模型（LLM）核心技术"></a>第一章：大语言模型（LLM）核心技术</h2><h3 id="1-1-核心定义与特性"><a href="#1-1-核心定义与特性" class="headerlink" title="1.1 核心定义与特性"></a>1.1 核心定义与特性</h3><ul>
<li><strong>定义</strong>: 基于深度学习的超大规模语言模型（参数规模达10^11~10^12量级）</li>
<li><strong>典型代表</strong>:<ul>
<li>GPT-3&#x2F;4（OpenAI）</li>
<li>PaLM（Google）</li>
<li>Llama（Meta）</li>
</ul>
</li>
<li><strong>三大核心特征</strong>：<ol>
<li><strong>大规模参数</strong>: 如GPT-3含1750亿参数</li>
<li><strong>海量训练数据</strong>: GPT-3训练数据包含数千亿单词</li>
<li><strong>算力密集型</strong>: 依赖GPU&#x2F;TPU集群进行训练</li>
</ol>
</li>
</ul>
<h3 id="1-2-Transformer架构"><a href="#1-2-Transformer架构" class="headerlink" title="1.2 Transformer架构"></a>1.2 Transformer架构</h3><ul>
<li><strong>核心创新</strong>:<ul>
<li><a href="#">自注意力机制</a>（Self-Attention）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自注意力计算伪代码</span></span><br><span class="line">Q = query @ W_Q</span><br><span class="line">K = key @ W_K</span><br><span class="line">V = value @ W_V</span><br><span class="line">attention = softmax(Q @ K.T / sqrt(d_k)) @ V</span><br></pre></td></tr></table></figure></li>
<li><a href="#">并行计算优势</a>: 相较RNN显著提升训练速度</li>
<li>多层堆叠结构（编码器&#x2F;解码器）</li>
</ul>
</li>
<li><strong>演进路线</strong>:<br><code>Transformer → GPT → GPT-3/4</code>（仅用解码器架构）</li>
</ul>
<h3 id="1-3-Token"><a href="#1-3-Token" class="headerlink" title="1.3 Token"></a>1.3 Token</h3><h4 id="一、什么是-Token？"><a href="#一、什么是-Token？" class="headerlink" title="一、什么是 Token？"></a>一、什么是 Token？</h4><ol>
<li><p><strong>定义</strong></p>
<p>Token 可以是单词、子词（subword）、字符或符号。例如：</p>
<ul>
<li>英文中，单词 <code>&quot;unhappy&quot;</code> 可能被拆分为两个子词：<code>&quot;un&quot;</code> + <code>&quot;happy&quot;</code>。</li>
<li>中文中，<code>&quot;自然语言处理&quot;</code> 可能被拆分为单个字符（如 <code>&quot;自&quot;</code>, <code>&quot;然&quot;</code>, <code>&quot;语&quot;</code>…）或词语（如 <code>&quot;自然&quot;</code>, <code>&quot;语言&quot;</code>, <code>&quot;处理&quot;</code>）。</li>
</ul>
</li>
<li><p><strong>Tokenization（分词）</strong></p>
<p>将原始文本分割成 Token 的过程称为  <strong>Tokenization</strong> 。例如：</p>
<ul>
<li>英文句子 <code>&quot;I love AI!&quot;</code> → Tokens: <code>[&quot;I&quot;, &quot;love&quot;, &quot;AI&quot;, &quot;!&quot;]</code>。</li>
<li>中文句子 <code>&quot;你好，世界！&quot;</code> → Tokens: <code>[&quot;你&quot;, &quot;好&quot;, &quot;，&quot;, &quot;世&quot;, &quot;界&quot;, &quot;！&quot;]</code>（按字符拆分）。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="二、为什么需要-Token？"><a href="#二、为什么需要-Token？" class="headerlink" title="二、为什么需要 Token？"></a>二、为什么需要 Token？</h4><ol>
<li><p><strong>模型的输入限制</strong></p>
<p>语言模型（如 GPT、LLaMA）有固定的  <strong>上下文窗口长度</strong> （例如 4k&#x2F;32k Tokens）。Token 的数量直接决定了模型能处理的文本长度。</p>
</li>
<li><p><strong>跨语言兼容性</strong></p>
<ul>
<li>英文等空格分隔的语言，通常以单词或子词为 Token。</li>
<li>中文、日文等无空格语言，常以字符或词语为 Token，这对模型处理不同语言更灵活。</li>
</ul>
</li>
<li><p><strong>效率与语义平衡</strong></p>
<ul>
<li>用单词作为 Token：语义明确，但词汇表过大（例如英文有百万级单词）。</li>
<li>用子词或字符作为 Token：词汇表小，能处理未知词汇（如 <code>&quot;ChatGPT&quot;</code> → <code>&quot;Chat&quot;</code> + <code>&quot;G&quot;</code> + <code>&quot;PT&quot;</code>）。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="三、Token-如何影响模型？"><a href="#三、Token-如何影响模型？" class="headerlink" title="三、Token 如何影响模型？"></a>三、Token 如何影响模型？</h4><ol>
<li><p><strong>计算资源</strong></p>
<p>Token 数量直接影响模型的计算量和内存占用。例如，处理 1000 个 Token 比 100 个 Token 更耗资源。</p>
</li>
<li><p><strong>文本生成限制</strong></p>
<p>模型生成的文本长度通常以 Token 数衡量。例如，设置 <code>max_tokens=50</code> 表示模型最多输出 50 个 Token。</p>
</li>
<li><p><strong>分词差异</strong></p>
<p>不同模型使用不同的分词器（Tokenizer）：</p>
<ul>
<li><strong>英文</strong> ：GPT 系列用  <strong>Byte-Pair Encoding (BPE)</strong> ，BERT 用  <strong>WordPiece</strong> 。</li>
<li><strong>中文</strong> ：部分模型按字符分词，部分按词语分词（如 <code>&quot;清华大学&quot;</code> → <code>&quot;清华&quot;</code> + <code>&quot;大学&quot;</code>）。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="四、实际应用示例"><a href="#四、实际应用示例" class="headerlink" title="四、实际应用示例"></a>四、实际应用示例</h4><ol>
<li><p><strong>输入输出长度</strong></p>
<p>一段 500 字的中文文章，按字符分词可能需要约  <strong>500-700 Tokens</strong> （标点、空格等占用额外 Token）。</p>
</li>
<li><p><strong>API 调用参数</strong></p>
<p>使用 OpenAI API 时，需注意 <code>max_tokens</code> 参数。例如，若输入已占 3800 Tokens（GPT-4 上限为 4096），则最多只能生成  <strong>296 个 Token</strong> 。</p>
</li>
<li><p><strong>分词工具测试</strong></p>
<p>可通过开源工具（如 <a target="_blank" rel="noopener" href="https://platform.openai.com/tokenizer">OpenAI Tokenizer</a>）测试文本的 Token 拆分结果。</p>
</li>
</ol>
<hr>
<h4 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h4><ul>
<li>Token 是语言模型的“通用货币”，直接影响模型处理文本的能力。</li>
<li>分词方式因模型而异，同一段文本在不同模型中的 Token 数量可能不同。</li>
<li>理解 Token 有助于优化输入输出长度、控制 API 成本，并深入理解模型的工作原理。</li>
</ul>
<hr>
<h2 id="第二章：AI模型分类体系"><a href="#第二章：AI模型分类体系" class="headerlink" title="第二章：AI模型分类体系"></a>第二章：AI模型分类体系</h2><h3 id="2-1-分类维度"><a href="#2-1-分类维度" class="headerlink" title="2.1 分类维度"></a>2.1 分类维度</h3><table>
<thead>
<tr>
<th>分类依据</th>
<th>典型类别</th>
<th>技术特点差异</th>
</tr>
</thead>
<tbody><tr>
<td>功能目标</td>
<td>对话模型&#x2F;代码生成模型</td>
<td>任务目标与评估指标不同</td>
</tr>
<tr>
<td>数据模态</td>
<td>文本模型&#x2F;多模态模型</td>
<td>输入的预处理方式差异</td>
</tr>
<tr>
<td>部署形式</td>
<td>云端大模型&#x2F;端侧小模型</td>
<td>参数量与计算资源需求</td>
</tr>
</tbody></table>
<h3 id="2-2-典型模型详解"><a href="#2-2-典型模型详解" class="headerlink" title="2.2 典型模型详解"></a>2.2 典型模型详解</h3><h4 id="对话模型（Chat-Model）"><a href="#对话模型（Chat-Model）" class="headerlink" title="对话模型（Chat Model）"></a>对话模型（Chat Model）</h4><ul>
<li><strong>核心功能</strong>: 人机多轮自然对话</li>
<li><strong>关键技术</strong>:<ul>
<li>指令微调（Instruction Tuning）</li>
<li>RLHF对齐技术</li>
</ul>
</li>
<li><strong>应用案例</strong>:<blockquote>
<p>ChatGPT处理客服咨询：<br>用户：”订单未及时送达如何处理？”<br>系统检索物流政策→生成方案：”经查询，可为您申请运费补偿…”</p>
</blockquote>
</li>
</ul>
<h4 id="代码生成模型（Coder-Model）"><a href="#代码生成模型（Coder-Model）" class="headerlink" title="代码生成模型（Coder Model）"></a>代码生成模型（Coder Model）</h4><ul>
<li><strong>典型架构</strong>:<pre class="mermaid">  graph LR
  A[输入:自然语言描述] --> B[代码语法解析]
  B --> C[抽象语法树生成]
  C --> D[代码优化器]
  D --> E[输出:可执行代码]</pre></li>
<li><strong>开发工具链</strong>:<br>IDE插件 → GitHub Copilot → 自动代码补全</li>
</ul>
<h4 id="多模态模型"><a href="#多模态模型" class="headerlink" title="多模态模型"></a>多模态模型</h4><table>
<thead>
<tr>
<th>模态类型</th>
<th>典型模型</th>
<th>输入&#x2F;输出实例</th>
</tr>
</thead>
<tbody><tr>
<td>文本→图像</td>
<td>Stable Diffusion</td>
<td>“赛博朋克风格的机械猫” → 🖼️</td>
</tr>
<tr>
<td>音频→文本</td>
<td>Whisper</td>
<td>🎤语音输入 → 📝会议纪要</td>
</tr>
<tr>
<td>视频生成</td>
<td>Sora</td>
<td>“丛林瀑布场景” → 🎬30秒视频</td>
</tr>
</tbody></table>
<h4 id="嵌入模型（Embedding-Model）"><a href="#嵌入模型（Embedding-Model）" class="headerlink" title="嵌入模型（Embedding Model）"></a>嵌入模型（Embedding Model）</h4><ul>
<li><strong>定义</strong>：将文本&#x2F;图像转换为低维向量（即向量“嵌入”），用于语义理解。</li>
<li><strong>技术特点</strong>：<ul>
<li>向量编码保留了语义相似性（如“猫”和“狗”向量距离较近）。</li>
<li>通常作为下游任务的预处理工具（如检索、分类）。</li>
</ul>
</li>
<li><strong>例子</strong>：<ul>
<li><strong>text-embedding-3-small</strong>（OpenAI）：文本嵌入的高效模型。</li>
<li><strong>CLIP</strong>（OpenAI）：跨模态嵌入（图像与文本的联合向量空间）。</li>
</ul>
</li>
<li><strong>为什么需要</strong>：向量数据库搜索、推荐系统、知识图谱的构建基础。</li>
</ul>
<h2 id="第三章：检索增强生成（RAG）技术体系"><a href="#第三章：检索增强生成（RAG）技术体系" class="headerlink" title="第三章：检索增强生成（RAG）技术体系"></a>第三章：检索增强生成（RAG）技术体系</h2><h3 id="3-1-RAG-的定义"><a href="#3-1-RAG-的定义" class="headerlink" title="3.1 RAG 的定义"></a>3.1 RAG 的定义</h3><ul>
<li><p>是的，<strong>RAG是一个技术框架的名称</strong>，代表“大模型（LLM）+ 知识库（向量索引）的协作模式”。但需注意几点细节：</p>
<p>-<strong>知识库未必完全由用户私有数据构成</strong>：例如，你可以结合通用知识库（如维基百科向量化）和私有数据。</p>
<p>-<strong>嵌模型的作用是转化，但非“让AI理解”</strong>：向量化的本质是将文本映射到高维空间，相似语义的文本向量距离更近，从而支持快速检索。模型本身仍然需要理解上下文。</p>
</li>
</ul>
<h3 id="3-2-流程拆解"><a href="#3-2-流程拆解" class="headerlink" title="3.2 流程拆解"></a>3.2 流程拆解</h3><p>RAG 的核心是将<strong>用户私有知识</strong>与<strong>大模型通用能力</strong>结合，具体步骤如下：</p>
<p>1.<strong>数据准备（用户专业知识）</strong>：</p>
<ul>
<li>原始形式：PDF、TXT、数据库记录、网页内容等（例如企业内部的合同、产品手册）。</li>
</ul>
<p>2.<strong>数据转化</strong>：</p>
<ul>
<li>用<strong>嵌入模型（Embedding Model）</strong>将文本转化为<strong>向量（Vector）</strong>，而不是某种“AI方便理解的数据”（更准确的说法是：向量是机器学习模型能够高效处理的高维数学表示）。</li>
</ul>
<p>3.<strong>存储为知识库</strong>：</p>
<ul>
<li>向量存入<strong>向量数据库</strong>（如Chroma、Pinecone），并保留原始文本的映射关系。这被称为“知识库”，但更技术化的术语是<strong>向量索引（Vector Index）</strong>。</li>
</ul>
<p>4.<strong>检索与生成</strong>：</p>
<ul>
<li>用户提问时，RAG 框架将问题转化为向量 → 从向量数据库检索相似内容 → 将检索到的文本作为上下文输入大模型（如 GPT-4）→ 生成最终回答。</li>
</ul>
<h3 id="3-3RAG-运作流程图解"><a href="#3-3RAG-运作流程图解" class="headerlink" title="3.3RAG 运作流程图解"></a>3.3RAG 运作流程图解</h3><pre class="mermaid">
graph TD

    A[用户问题] --> B[问题向量化<br/>嵌入模型处理]

    B --> C{向量数据库检索}

    C -->|相似度 > 阈值| D[召回匹配文本片段]

    C -->|无匹配结果| E[触发失败处理]

    D --> F[构造上下文 Prompt]

    F --> G[大模型生成答案]

    E --> H[基于大模型原生知识生成]

    G --> I[最终回答]

    H --> I</pre>

<hr>
<h3 id="3-4流程分步详解"><a href="#3-4流程分步详解" class="headerlink" title="3.4流程分步详解"></a>3.4流程分步详解</h3><h4 id="1-用户问题向量化"><a href="#1-用户问题向量化" class="headerlink" title="1. 用户问题向量化"></a>1. 用户问题向量化</h4><p>*<strong>技术实现</strong> ：</p>
<p>  使用嵌入模型（如 OpenAI 的 <code>text-embedding-3-small</code>）将问题文本转化为 <strong>高维向量</strong> 。</p>
<p>  示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">问题：“如何重置密码？” → 向量 = [0.23, -0.45, 1.2, ..., 1536维]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>*<strong>关键细节</strong> ：</p>
<ul>
<li>向量维度由模型决定（如 OpenAI 默认 1536 维）。</li>
<li>语义相似的文本向量在空间中距离更近（余弦相似度高）。</li>
</ul>
<h4 id="2-向量数据库匹配"><a href="#2-向量数据库匹配" class="headerlink" title="2. 向量数据库匹配"></a>2. 向量数据库匹配</h4><p>*<strong>匹配逻辑</strong> ：</p>
<ul>
<li>计算问题向量与知识库中所有向量的 <strong>余弦相似度</strong> 。</li>
<li>按相似度从高到低返回 Top K 个结果（如 K&#x3D;3）。</li>
</ul>
<p>*<strong>阈值控制（可选）</strong> ：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">if 最高相似度 &lt; 阈值（如 0.7）→ 视为“未匹配到知识库内容”  </span><br><span class="line"></span><br><span class="line">else → 使用检索到的文本  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3-匹配成功：基于知识库回答"><a href="#3-匹配成功：基于知识库回答" class="headerlink" title="3. 匹配成功：基于知识库回答"></a>3. 匹配成功：基于知识库回答</h4><ul>
<li><p><strong>上下文构造</strong> ：</p>
<p>将检索到的文本片段插入 Prompt，引导大模型基于此生成答案。</p>
<p>示例 Prompt：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;spanclass=&quot;line&quot;&gt;&lt;span&gt;【检索到的内容】：&quot;用户可在设置页面的‘账户安全’中选择‘忘记密码’，系统将发送重置链接至注册邮箱。&quot;  &lt;/span&gt;&lt;/span&gt;</span><br><span class="line"></span><br><span class="line">&lt;spanclass=&quot;line&quot;&gt;&lt;span&gt;问题：如何重置密码？  &lt;/span&gt;&lt;/span&gt;</span><br><span class="line"></span><br><span class="line">&lt;spanclass=&quot;line&quot;&gt;&lt;span&gt;答案：  &lt;/span&gt;&lt;/span&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>输出约束</strong> ：</li>
</ul>
<p>大模型 <strong>必须优先依赖检索到的内容</strong> ，即使其自身知识库中存在不同答案。</p>
<h4 id="4-匹配失败：大模型自主回答"><a href="#4-匹配失败：大模型自主回答" class="headerlink" title="4. 匹配失败：大模型自主回答"></a>4. 匹配失败：大模型自主回答</h4><p>*<strong>风险点</strong> ：</p>
<ul>
<li>模型可能因知识截止（如 GPT-4 知识止于 2023年4月）给出过时信息。</li>
</ul>
<p>*<strong>幻觉风险</strong> ：对未知领域问题编造不合理答案（如虚构产品功能）。</p>
<p>*<strong>缓解策略</strong> ：</p>
<ol>
<li><p>显式声明来源：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（检测到无相关文档）→ 回答前标注：“根据通用知识，可能存在偏差...”  </span><br></pre></td></tr></table></figure></li>
<li><p>拒绝回答：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“抱歉，我的知识库暂未收录此问题的相关信息。”  </span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-5类比"><a href="#3-5类比" class="headerlink" title="3.5类比"></a>3.5类比</h3><h4 id="律师-手册"><a href="#律师-手册" class="headerlink" title="律师 + 手册"></a>律师 + 手册</h4><p>想象你是一名律师，处理案件时需要：</p>
<ul>
<li><strong>知识库</strong> &#x3D; 法律条文手册（你预先准备的参考资料）。</li>
<li><strong>检索</strong> &#x3D; 根据案情快速翻到相关法条目录。</li>
<li><strong>生成</strong> &#x3D; 结合法律条文和案情分析，写出辩护词。<br>在这个过程中，法律条文手册是“知识库”，你的翻查动作是“检索”，最终的辩护词是“大模型生成”。</li>
</ul>
<h4 id="菜鸟厨师-食材检索系统"><a href="#菜鸟厨师-食材检索系统" class="headerlink" title="菜鸟厨师 + 食材检索系统"></a>菜鸟厨师 + 食材检索系统</h4><ul>
<li>大模型 → <strong>厨艺新手</strong>：能按步骤做菜，但不知道特定食材在哪。</li>
<li>知识库 → <strong>智能食材柜</strong>：通过扫描菜名自动弹出相关原料（如输入“宫保鸡丁” → 提供花生、鸡肉、辣椒）。</li>
<li>RAG → <strong>全流程</strong>：<code>&lt;br&gt;</code> 用户要“做宫保鸡丁” → 厨师自己不会备菜，必须从食材柜中拿指定原料 → 结合菜谱书（模型的知识）完成烹饪。</li>
</ul>
<h4 id="客服专员-知识库搜索引擎"><a href="#客服专员-知识库搜索引擎" class="headerlink" title="客服专员 + 知识库搜索引擎"></a>客服专员 + 知识库搜索引擎</h4><ul>
<li>大模型 → <strong>普通客服人员</strong>：受过基础培训，但没看过公司内部文档。</li>
<li>知识库 → <strong>内部文档系统</strong>：输入用户问题后自动高亮相关文档片段。</li>
<li>RAG → <strong>操作流程</strong>：<code>&lt;br&gt;</code> 用户问“退货政策是什么？” → 客服打开文档系统，检索出最新条款 → 根据条款原文整理成回答告知用户。</li>
</ul>
<h3 id="3-5常见的误解修正"><a href="#3-5常见的误解修正" class="headerlink" title="3.5常见的误解修正"></a>3.5常见的误解修正</h3><h4 id="误解-1：“嵌入模型直接将知识传授给-AI”"><a href="#误解-1：“嵌入模型直接将知识传授给-AI”" class="headerlink" title="误解 1：“嵌入模型直接将知识传授给 AI”"></a><strong>误解 1</strong>：“嵌入模型直接将知识传授给 AI”</h4><ul>
<li>❌ <strong>错误点</strong>：嵌入模型仅负责将文本转化为向量，<strong>不修改大模型（如 GPT-4）的原始知识</strong>，仅通过检索机制动态注入上下文。</li>
<li>✅ <strong>正确理解</strong>：RAG 通过上下文增强，但大模型本身的知识未改变（对比微调才会修改模型参数）。</li>
</ul>
<h4 id="误解-2：“知识库是某种特殊数据结构”"><a href="#误解-2：“知识库是某种特殊数据结构”" class="headerlink" title="误解 2：“知识库是某种特殊数据结构”"></a><strong>误解 2</strong>：“知识库是某种特殊数据结构”</h4><ul>
<li>❌ <strong>错误点</strong>：知识库本质上是一个<strong>索引系统</strong>，包含向量和原始文本的对应关系，技术上可能是一个数据库表或文件。</li>
<li>✅ <strong>正确理解</strong>：知识库的构建流程如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">原始文本 → 分块（Chunking）→ 向量化 → 存储在向量数据库（如：&#123;向量, 文本, 元数据&#125;）</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="误解-3：“RAG-只是把数据灌给模型”"><a href="#误解-3：“RAG-只是把数据灌给模型”" class="headerlink" title="误解 3：“RAG 只是把数据灌给模型”"></a><strong>误解 3</strong>：“RAG 只是把数据灌给模型”</h4><ul>
<li>✅ <strong>技术本质</strong>：RAG 的意义在于解决大模型的以下问题：<ol>
<li><strong>知识截止（Cut-off Date）</strong>：大模型的知识停留在训练时间（如 GPT-4 知识截止到 2023年4月）。</li>
<li><strong>隐私与安全</strong>：直接微调可能泄露敏感数据，而 RAG 通过检索权限控制数据可见性。</li>
<li><strong>成本效率</strong>：动态检索比微调更灵活，无需重新训练模型。</li>
</ol>
</li>
</ul>
<h4 id="偏差点-1：大模型的“主动性”问题"><a href="#偏差点-1：大模型的“主动性”问题" class="headerlink" title="偏差点 1：大模型的“主动性”问题"></a><strong>偏差点 1：大模型的“主动性”问题</strong></h4><ul>
<li>❌ 误解：大模型像人脑一样主动思考。</li>
<li>✅ 纠正：大模型在 RAG 中是<strong>被动执行者</strong>，必须严格基于检索结果生成内容。例如：<ul>
<li>若检索到错误内容，模型可能生成错误答案（尽管自身知识正确）。</li>
<li>若检索无结果，模型只能依赖自身知识回答（可能导致幻觉）。</li>
</ul>
</li>
</ul>
<h4 id="偏差点-2：知识库的检索精度"><a href="#偏差点-2：知识库的检索精度" class="headerlink" title="偏差点 2：知识库的检索精度"></a><strong>偏差点 2：知识库的检索精度</strong></h4><ul>
<li>❌ 误解：像查手册一样“人工翻阅找到相关内容”。</li>
<li>✅ 纠正：RAG 检索依赖<strong>数学计算的语义匹配</strong>，而非人工逻辑。<ul>
<li><strong>极端案例</strong>：用户问“如何治疗流感？” → 若知识库中存在“禽流感疫苗研发文档”且语义向量接近，可能被错误检索。</li>
</ul>
</li>
</ul>
<h4 id="偏差点-3：RAG-的可靠性边界"><a href="#偏差点-3：RAG-的可靠性边界" class="headerlink" title="偏差点 3：RAG 的可靠性边界"></a><strong>偏差点 3：RAG 的可靠性边界</strong></h4><ul>
<li>❌ 误解：只要用了 RAG，答案一定准确。</li>
<li>✅ 现实：RAG 的效果取决于三大因素：<ol>
<li><strong>嵌入模型质量</strong>：差的模型无法正确向量化文本（如“汽车”和“轮胎”可能被误判为无关）。</li>
<li><strong>检索策略</strong>：分块（Chunking）大小、是否过滤元数据（如文档更新时间）。</li>
<li><strong>大模型的上下文理解能力</strong>：模型能否正确利用检索到的文本。</li>
</ol>
</li>
</ul>
<h3 id="3-6总结"><a href="#3-6总结" class="headerlink" title="3.6总结"></a>3.6总结</h3><p>如何记住 RAG 的本质？<br>用三个关键词代替比喻：</p>
<ol>
<li><strong>动态缝合</strong>（Stitching） → 将外部知识“缝”进模型的上下文窗口。</li>
<li><strong>数学驱动</strong>（Vector Math） → 检索靠向量相似度计算，非人类逻辑。</li>
<li><strong>上下文约束</strong>（Constrained Generation） → 模型输出被检索内容严格限制。</li>
</ol>
<h2 id="第四章Prompt（提示提示词）"><a href="#第四章Prompt（提示提示词）" class="headerlink" title="第四章Prompt（提示提示词）"></a>第四章Prompt（提示提示词）</h2><p>在大型语言模型（LLM）中，<strong>prompt（提示词）</strong> 是用户与模型交互的核心工具，其作用可以总结为以下几点：</p>
<hr>
<h3 id="4-1-定义任务目标"><a href="#4-1-定义任务目标" class="headerlink" title="4.1 定义任务目标"></a>4.1 <strong>定义任务目标</strong></h3><ul>
<li><strong>作用</strong>：Prompt 是用户向模型传达意图的桥梁，明确告诉模型“需要完成什么任务”。</li>
<li><strong>示例</strong>：<ul>
<li>模糊的提问：“关于气候变化。”<br>→ 模型可能输出泛泛而谈的内容。</li>
<li>明确的指令：“用500字总结气候变化的成因、影响和解决方案。”<br>→ 模型生成结构化、针对性强的回答。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-2-控制输出风格与格式"><a href="#4-2-控制输出风格与格式" class="headerlink" title="4.2 控制输出风格与格式"></a>4.2 <strong>控制输出风格与格式</strong></h3><ul>
<li><strong>作用</strong>：通过 Prompt 指定输出形式（如代码、诗歌、报告）、语气（专业、幽默）或结构（列表、表格、JSON）。</li>
<li><strong>示例</strong>：<ul>
<li>“用莎士比亚的风格写一首关于咖啡的十四行诗。”</li>
<li>“将以下数据转换为Markdown表格：…”</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-3-提供上下文与约束"><a href="#4-3-提供上下文与约束" class="headerlink" title="4.3 提供上下文与约束"></a>4.3 <strong>提供上下文与约束</strong></h3><ul>
<li><strong>作用</strong>：补充背景信息或限制条件，缩小模型生成范围，避免无关或错误内容。</li>
<li><strong>示例</strong>：<ul>
<li>“假设你是一名医生，如何解释高血压的成因？”<br>→ 模型会代入角色，生成符合医学知识的回答。</li>
<li>“仅用小学生能理解的词汇解释量子力学。”</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-4-激活特定知识或能力"><a href="#4-4-激活特定知识或能力" class="headerlink" title="4.4 激活特定知识或能力"></a>4.4 <strong>激活特定知识或能力</strong></h3><ul>
<li><strong>作用</strong>：LLM 具备海量知识，但需要 Prompt 明确调用特定领域或技能。</li>
<li><strong>示例</strong>：<ul>
<li>数学推理：“分步骤解答：鸡兔同笼问题，共有头10个，脚28只。”</li>
<li>代码生成：“用Python写一个快速排序算法，并添加注释。”</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-5-纠正偏差与安全对齐"><a href="#4-5-纠正偏差与安全对齐" class="headerlink" title="4.5 纠正偏差与安全对齐"></a>4.5 <strong>纠正偏差与安全对齐</strong></h3><ul>
<li><strong>作用</strong>：通过 Prompt 引导模型遵守伦理规范，避免有害、偏见或虚构内容。</li>
<li><strong>示例</strong>：<ul>
<li>“基于权威科学来源，回答地球是否平。”<br>→ 限制模型输出科学共识，而非伪科学观点。</li>
<li>“以中立态度比较不同政治制度的优缺点。”</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-6-提升效率（Few-shot-Learning）"><a href="#4-6-提升效率（Few-shot-Learning）" class="headerlink" title="4.6 提升效率（Few-shot Learning）"></a>4.6 <strong>提升效率（Few-shot Learning）</strong></h3><ul>
<li><strong>作用</strong>：在 Prompt 中提供示例（Few-shot），显著提升模型在复杂任务中的表现。</li>
<li><strong>示例</strong>：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">任务：将中文俚语翻译成英文，并解释含义。</span><br><span class="line">示例：</span><br><span class="line">输入：躺平</span><br><span class="line">输出：Lie flat. 含义：指拒绝过度竞争，选择低欲望的生活方式。</span><br><span class="line">输入：内卷</span><br><span class="line">输出：...</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="4-7-动态调整模型行为"><a href="#4-7-动态调整模型行为" class="headerlink" title="4.7 动态调整模型行为"></a>4.7 <strong>动态调整模型行为</strong></h3><ul>
<li><strong>作用</strong>：通过修改 Prompt 调整模型的“性格”或交互模式（如严谨&#x2F;创意模式）。</li>
<li><strong>示例</strong>：<ul>
<li>“你是一个严格的历史学家，只回答有文献证据支持的内容。”</li>
<li>“用比喻和故事解释相对论。”</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-8-关键挑战与优化"><a href="#4-8-关键挑战与优化" class="headerlink" title="4.8 关键挑战与优化"></a>4.8 关键挑战与优化</h3><ul>
<li><strong>Prompt Engineering</strong>：设计高质量 Prompt 需要技巧，例如：<ul>
<li>明确性（避免歧义）</li>
<li>结构化（分步骤、分条件）</li>
<li>测试迭代（根据输出调整表述）。</li>
</ul>
</li>
<li><strong>局限性</strong>：过度依赖 Prompt 可能导致“幻觉”（虚构事实）或格式错误，需结合模型微调或外部验证。</li>
</ul>
<hr>
<h3 id="4-9-总结"><a href="#4-9-总结" class="headerlink" title="4.9 总结"></a>4.9 总结</h3><p>Prompt 是用户“编程”LLM 的核心工具，通过自然语言指令调动模型的知识、推理和生成能力。其设计直接影响输出的质量、准确性和适用性，因此 <strong>Prompt Engineering（提示词工程）</strong> 已成为高效使用 LLM 的关键技能。</p>
<h2 id="第五章AI-Agent（人工智能代理）"><a href="#第五章AI-Agent（人工智能代理）" class="headerlink" title="第五章AI Agent（人工智能代理）"></a>第五章AI Agent（人工智能代理）</h2><h3 id="5-1-AI-Agent的定义与核心特性"><a href="#5-1-AI-Agent的定义与核心特性" class="headerlink" title="5.1 AI Agent的定义与核心特性"></a><strong>5.1 AI Agent的定义与核心特性</strong></h3><p><strong>AI Agent</strong> 是指能够<strong>自主感知环境、分析信息、制定决策并采取行动</strong>以实现特定目标的人工智能实体。它不局限于单一任务，而是通过与环境互动持续优化行为，具备一定程度的自主性和适应性。</p>
<p><strong>个人理解：</strong></p>
<blockquote>
<p>是 基于LLM 和一些工具箱 ，给LLM 输出格式进行限制 然后程序对这个格式进行解析调用相关的工具将输出再给LLM这样一步步最终得到想要的结果</p>
</blockquote>
<hr>
<h3 id="5-2-核心流程概览"><a href="#5-2-核心流程概览" class="headerlink" title="5.2 核心流程概览"></a><strong>5.2 核心流程概览</strong></h3><pre class="mermaid">graph LR
A[用户输入] --> B{LLM} 
B -->|结构化指令| C[程序解析]
C -->|调用工具| D[工具箱]
D -->|工具结果| B
B -->|最终输出| E[用户]</pre>

<ol>
<li><p><strong>输入与格式约束</strong></p>
<ul>
<li><strong>Prompt设计</strong>：通过 <strong>结构化指令模板</strong>（如JSON、XML或自定义标记）限制LLM输出格式。<br><em>例</em>：<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;请按以下格式回复：&#123; &#x27;action&#x27;: &#x27;search&#x27;, &#x27;query&#x27;: &#x27;关键词&#x27; &#125;&quot;</span> </span><br></pre></td></tr></table></figure></li>
<li><strong>输出标准化</strong>：确保LLM返回的指令可被程序解析（如避免自然语言描述，强制字段必填）。</li>
</ul>
</li>
<li><p><strong>工具解析与调用</strong></p>
<ul>
<li><strong>程序解析模块</strong>：提取LLM输出中的动作指令（如 <code>action</code>字段）和参数（如 <code>query</code>）。</li>
<li><strong>工具映射</strong>：根据动作指令匹配预定义的工具函数（如 <code>search</code>→联网搜索API）。</li>
</ul>
</li>
<li><p><strong>结果反馈与迭代</strong></p>
<ul>
<li><strong>工具执行结果</strong>：将工具返回的数据（如搜索结果、数据库信息）重新输入LLM。</li>
<li><strong>多轮交互</strong>：LLM可能需多次调用工具，直到满足终止条件（如用户问题解决）。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-3-AI-Agent-的核心组成部分"><a href="#5-3-AI-Agent-的核心组成部分" class="headerlink" title="5.3 AI Agent 的核心组成部分"></a><strong>5.3 AI Agent 的核心组成部分</strong></h3><ol>
<li><p><strong>感知（Perception）</strong></p>
<ul>
<li>通过传感器、数据输入或用户交互（如文字、图像、语音）获取环境信息。</li>
<li><strong>示例</strong>：自动驾驶汽车通过摄像头和雷达感知路况。</li>
</ul>
</li>
<li><p><strong>决策（Decision-Making）</strong></p>
<ul>
<li>基于感知信息，利用算法（规则引擎、机器学习模型等）分析并生成行动策略。</li>
<li><strong>示例</strong>：电商推荐系统根据用户行为数据决定推送哪些商品。</li>
</ul>
</li>
<li><p><strong>执行（Action）</strong></p>
<ul>
<li>将决策转化为实际动作，可能包括物理操作（如机器人移动）或数字输出（如生成文本）。</li>
<li><strong>示例</strong>：聊天机器人根据对话内容生成回复。</li>
</ul>
</li>
<li><p><strong>学习与适应（Learning）</strong></p>
<ul>
<li>通过反馈（如用户评价、环境变化）优化模型，提升长期表现。</li>
<li><strong>示例</strong>：游戏AI通过强化学习不断改进策略以击败对手。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-4-AI-Agent-的分类"><a href="#5-4-AI-Agent-的分类" class="headerlink" title="5.4 AI Agent 的分类"></a><strong>5.4 AI Agent 的分类</strong></h3><table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>特点</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>反应式 Agent</strong></td>
<td>仅根据当前输入即时响应，无长期记忆或目标。</td>
<td>温度传感器触发空调开关。</td>
</tr>
<tr>
<td><strong>基于目标的 Agent</strong></td>
<td>围绕预设目标规划行动，权衡短期与长期收益。</td>
<td>物流调度系统优化配送路线。</td>
</tr>
<tr>
<td><strong>基于效用的 Agent</strong></td>
<td>引入“效用函数”评估不同行动的价值，选择最优解。</td>
<td>金融交易Agent最大化投资收益。</td>
</tr>
<tr>
<td><strong>学习型 Agent</strong></td>
<td>通过数据或交互经验动态调整策略（如强化学习）。</td>
<td>AlphaGo 自我对弈提升棋艺。</td>
</tr>
<tr>
<td><strong>多 Agent 系统</strong></td>
<td>多个Agent协作或竞争，通过通信和博弈实现复杂目标。</td>
<td>自动驾驶车辆协同避免交通拥堵。</td>
</tr>
</tbody></table>
<hr>
<h3 id="5-5-AI-Agent-的典型应用场景"><a href="#5-5-AI-Agent-的典型应用场景" class="headerlink" title="5.5 AI Agent 的典型应用场景"></a><strong>5.5 AI Agent 的典型应用场景</strong></h3><ol>
<li><p><strong>自动驾驶</strong></p>
<ul>
<li>感知路况→规划路径→控制车辆，实现安全驾驶。</li>
</ul>
</li>
<li><p><strong>智能助手</strong></p>
<ul>
<li>理解用户需求→调用API（如查天气、订机票）→返回结果（如Siri、Copilot）。</li>
</ul>
</li>
<li><p><strong>工业自动化</strong></p>
<ul>
<li>机器人通过视觉识别零件→调整动作完成装配。</li>
</ul>
</li>
<li><p><strong>游戏与虚拟世界</strong></p>
<ul>
<li>NPC根据玩家行为动态调整剧情或战斗策略（如《荒野大镖客2》中的AI角色）。</li>
</ul>
</li>
<li><p><strong>医疗诊断</strong></p>
<ul>
<li>分析患者数据→生成诊疗建议→跟踪疗效并调整方案。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-6-AI-Agent-与LLM的关系"><a href="#5-6-AI-Agent-与LLM的关系" class="headerlink" title="5.6 AI Agent 与LLM的关系"></a><strong>5.6 AI Agent 与LLM的关系</strong></h3><ul>
<li><strong>LLM作为“大脑”</strong>：大语言模型（如GPT-4）常被集成到Agent中，负责语言理解、推理和生成。</li>
<li><strong>增强自主性</strong>：通过Prompt工程或工具调用（Tools），LLM可驱动Agent完成复杂任务链（如联网搜索→分析→生成报告）。</li>
<li><strong>局限性</strong>：LLM的“幻觉”问题可能导致Agent决策错误，需结合外部知识库或验证机制。</li>
</ul>
<hr>
<h3 id="5-7-总结"><a href="#5-7-总结" class="headerlink" title="5.7 总结"></a><strong>5.7 总结</strong></h3><p>现代LLM Agent的核心架构:通过 <strong>结构化输出限制→程序化工具调用→循环迭代</strong>，LLM得以突破纯文本生成的局限，成为真正的“行动者”。未来随着 <strong>工具学习（Tool Learning）</strong> 和 <strong>程序合成（Program Synthesis）</strong> 的进步，这类Agent将能处理更复杂的跨模态任务（如调用机器人执行物理动作）。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/02/07/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/" rel="prev" title="浏览器开发工具">
                  <i class="fa fa-angle-left"></i> 浏览器开发工具
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/02/10/DeepSeek%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/" rel="next" title="DeepSeek部署记录">
                  DeepSeek部署记录 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">songyanglin</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">56k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">1:33</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.1/mermaid.min.js","integrity":"sha256-YbM1pG3wWnzhyYN49g5fPnen+2CKEFaZfopkkwSpNtY="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
